SimpleCnn(
  (conv1): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=1568, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
cuda is not avaiable.
==================================================
Algorithm: FedAvg
Local batch size: 10
Local epochs: 1
Local learing rate: 0.005
Local learing rate decay: False
Total number of clients: 20
Clients join in each round: 1.0
Clients randomly join: False
Client drop rate: 0.0
Client select regarding time: False
Running times: 1
Dataset: BloodMNIST
Number of classes: 10
Backbone: resnet18
Using device: cpu
Using DP: False
Auto break: False
Global rounds: 20
DLG attack: False
Total number of new clients: 0
Fine tuning epoches on new clients: 0
==================================================
============= Running time: 0th =============
Creating server and clients ...
x(
  (conv1): Conv2d(28, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): a(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): a(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): a(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (linear): Linear(in_features=512, out_features=10, bias=True)
  (fc): Linear(in_features=10, out_features=10, bias=True)
)
Join ratio / total clients: 1.0 / 20
Finished creating server and clients.
Dropped clients: [6, 15, 2, 7, 9, 4, 10, 18, 19, 0]
drop classif com
-------------Round number: 0-------------
Evaluate global model
Averaged Train Loss: 2.2691
Averaged Test Accurancy: 0.0703
Averaged Test AUC: 0.5693
Std Test Accurancy: 0.0527
Std Test AUC: 0.0483
clients: 10
Training client: 1, Time Cost: 3.2231059074401855, Train Accuracy: 50.00%
Training client: 3, Time Cost: 3.515432834625244, Train Accuracy: 43.87%
Training client: 5, Time Cost: 1.6255598068237305, Train Accuracy: 26.15%
Training client: 8, Time Cost: 4.005901336669922, Train Accuracy: 23.33%
Training client: 11, Time Cost: 5.549635648727417, Train Accuracy: 26.47%
Training client: 12, Time Cost: 4.239822864532471, Train Accuracy: 22.26%
Training client: 13, Time Cost: 5.4808666706085205, Train Accuracy: 40.28%
Training client: 14, Time Cost: 3.9866726398468018, Train Accuracy: 27.42%
Training client: 16, Time Cost: 3.6214253902435303, Train Accuracy: 37.33%
Training client: 17, Time Cost: 4.203326940536499, Train Accuracy: 26.47%
length of uploaded models 20
Dropped clients: [18, 8, 13, 2, 11, 19, 15, 3, 10, 1]
drop classif com
-------------Round number: 1-------------
Evaluate global model
Averaged Train Loss: 2.1830
Averaged Test Accurancy: 0.2289
Averaged Test AUC: 0.6984
Std Test Accurancy: 0.0862
Std Test AUC: 0.0555
clients: 10
Training client: 0, Time Cost: 3.493464946746826, Train Accuracy: 66.54%
Training client: 4, Time Cost: 3.9228813648223877, Train Accuracy: 46.33%
Training client: 5, Time Cost: 1.6133701801300049, Train Accuracy: 20.00%
Training client: 6, Time Cost: 2.4191699028015137, Train Accuracy: 62.11%
Training client: 7, Time Cost: 3.8549671173095703, Train Accuracy: 70.00%
Training client: 9, Time Cost: 3.279689073562622, Train Accuracy: 53.33%
Training client: 12, Time Cost: 4.062197685241699, Train Accuracy: 64.19%
Training client: 14, Time Cost: 3.459463357925415, Train Accuracy: 66.45%
Training client: 16, Time Cost: 3.404468297958374, Train Accuracy: 74.67%
Training client: 17, Time Cost: 3.803231954574585, Train Accuracy: 52.06%
length of uploaded models 20
Dropped clients: [9, 17, 1, 4, 11, 13, 3, 5, 12, 10]
drop classif com
-------------Round number: 2-------------
Evaluate global model
Averaged Train Loss: 1.5079
Averaged Test Accurancy: 0.4071
Averaged Test AUC: 0.8533
Std Test Accurancy: 0.1512
Std Test AUC: 0.0684
clients: 10
Training client: 0, Time Cost: 3.1179792881011963, Train Accuracy: 69.62%
Training client: 2, Time Cost: 4.1817121505737305, Train Accuracy: 67.78%
Training client: 6, Time Cost: 2.6356849670410156, Train Accuracy: 65.26%
Training client: 7, Time Cost: 3.1591389179229736, Train Accuracy: 65.00%
Training client: 8, Time Cost: 3.358046531677246, Train Accuracy: 55.67%
Training client: 14, Time Cost: 3.6032800674438477, Train Accuracy: 52.26%
Training client: 15, Time Cost: 4.402660131454468, Train Accuracy: 55.90%
Training client: 16, Time Cost: 3.7224512100219727, Train Accuracy: 76.67%
Training client: 18, Time Cost: 3.354196548461914, Train Accuracy: 66.25%
Training client: 19, Time Cost: 67.66709065437317, Train Accuracy: 67.94%
length of uploaded models 20
Dropped clients: [15, 2, 1, 0, 16, 19, 17, 4, 12, 11]
drop classif com
-------------Round number: 3-------------
Evaluate global model
Averaged Train Loss: 2.1706
Averaged Test Accurancy: 0.2766
Averaged Test AUC: 0.8062
Std Test Accurancy: 0.1202
Std Test AUC: 0.0650
clients: 10
Training client: 3, Time Cost: 3.8269150257110596, Train Accuracy: 87.74%
Training client: 5, Time Cost: 1.5618529319763184, Train Accuracy: 57.69%
Training client: 6, Time Cost: 2.3143529891967773, Train Accuracy: 50.00%
Training client: 7, Time Cost: 3.349174737930298, Train Accuracy: 79.29%
Training client: 8, Time Cost: 3.736856460571289, Train Accuracy: 78.67%
Training client: 9, Time Cost: 2.9459657669067383, Train Accuracy: 72.50%
Training client: 10, Time Cost: 4.889241933822632, Train Accuracy: 86.97%
Training client: 13, Time Cost: 4.743377447128296, Train Accuracy: 82.22%
Training client: 14, Time Cost: 3.7257866859436035, Train Accuracy: 80.65%
Training client: 18, Time Cost: 2.9482831954956055, Train Accuracy: 82.92%
length of uploaded models 20
Dropped clients: [5, 18, 15, 4, 17, 2, 12, 3, 14, 13]
drop classif com
-------------Round number: 4-------------
Evaluate global model
Averaged Train Loss: 1.3293
Averaged Test Accurancy: 0.5093
Averaged Test AUC: 0.9051
Std Test Accurancy: 0.1252
Std Test AUC: 0.0398
clients: 10
Training client: 0, Time Cost: 3.089742660522461, Train Accuracy: 45.77%
Training client: 1, Time Cost: 3.605992555618286, Train Accuracy: 85.17%
Training client: 6, Time Cost: 2.145195245742798, Train Accuracy: 78.95%
Training client: 7, Time Cost: 3.0925862789154053, Train Accuracy: 83.93%
Training client: 8, Time Cost: 3.2868592739105225, Train Accuracy: 74.00%
Training client: 9, Time Cost: 2.6593849658966064, Train Accuracy: 68.75%
Training client: 10, Time Cost: 3.6638638973236084, Train Accuracy: 84.55%
Training client: 11, Time Cost: 3.7574870586395264, Train Accuracy: 80.29%
Training client: 16, Time Cost: 4.042951345443726, Train Accuracy: 73.00%
Training client: 19, Time Cost: 72.53000283241272, Train Accuracy: 79.59%
length of uploaded models 20
Batch 1 clients: [5, 2, 4, 18, 7, 9, 0, 1, 3, 14, 8, 6]
Batch 2 clients: [10, 11, 12, 13, 15, 16, 17, 19]
hello
Batch 1 clients: [5, 2, 4, 18, 7, 9, 0, 1, 3, 14, 8, 6]
Batch 2 clients: [10, 11, 12, 13, 15, 16, 17, 19]
Training round 1/36 for batch 5
Training round 1/9 for batch 10<class 'list'>
<class 'list'>.........................
6.0.........................  .........................4.0
 .........................
Training client: 18, Time Cost: 32.309248208999634, Train Accuracy: 89.58%
Training client: 12, Time Cost: 38.89436101913452, Train Accuracy: 64.52%
Training client: 1, Time Cost: 38.27396631240845, Train Accuracy: 63.10%
Training client: 4, Time Cost: 38.481685400009155, Train Accuracy: 84.67%
Training client: 3, Time Cost: 39.75972890853882, Train Accuracy: 90.00%
Training client: 14, Time Cost: 39.81613516807556, Train Accuracy: 86.13%
Training client: 13, Time Cost: 43.285046339035034, Train Accuracy: 84.44%
Training client: 15, Time Cost: 44.295679330825806, Train Accuracy: 82.82%
Training client: 2, Time Cost: 41.67184066772461, Train Accuracy: 85.00%
......................... leng of drop and ffrnd
6
6
length of uploaded models 20
Training round 2/36 for batch 5
<class 'list'>
......................... 6.0 .........................
Training client: 7, Time Cost: 23.861326694488525, Train Accuracy: 54.29%
Training client: 1, Time Cost: 24.719600677490234, Train Accuracy: 85.86%
Training client: 8, Time Cost: 24.963427305221558, Train Accuracy: 92.00%
Training client: 4, Time Cost: 25.00117540359497, Train Accuracy: 62.67%
Training client: 3, Time Cost: 25.308542728424072, Train Accuracy: 81.94%
Training client: 2, Time Cost: 26.30778217315674, Train Accuracy: 82.78%
......................... leng of drop and ffrnd
6
6
length of uploaded models 20
Training round 3/36 for batch 5
<class 'list'>
......................... 6.0 .........................
Training client: 5, Time Cost: 12.267316579818726, Train Accuracy: 79.23%
Training client: 6, Time Cost: 18.041584968566895, Train Accuracy: 86.84%
Training client: 18, Time Cost: 20.651362419128418, Train Accuracy: 90.83%
Training client: 7, Time Cost: 22.908260345458984, Train Accuracy: 84.64%
Training client: 1, Time Cost: 23.292803287506104, Train Accuracy: 89.66%
Training client: 4, Time Cost: 23.487832069396973, Train Accuracy: 83.67%
......................... leng of drop and ffrnd
6
6
length of uploaded models 20
Training round 4/36 for batch 5
<class 'list'>
......................... 6.0 .........................
Training client: 6, Time Cost: 18.217787981033325, Train Accuracy: 88.42%
Training client: 0, Time Cost: 22.8205885887146, Train Accuracy: 77.69%
Training client: 7, Time Cost: 24.304237127304077, Train Accuracy: 66.07%
Training client: 1, Time Cost: 25.198663234710693, Train Accuracy: 82.07%
Training client: 14, Time Cost: 25.789740800857544, Train Accuracy: 86.13%
Training client: 2, Time Cost: 27.12962293624878, Train Accuracy: 80.00%
......................... leng of drop and ffrnd
6
6
length of uploaded models 20
Training round 5/36 for batch 5
<class 'list'>
......................... 6.0 .........................
Traceback (most recent call last):
  File "/home/student/R/fl/PFLlib/system/main.py", line 549, in <module>
    run(args)
  File "/home/student/R/fl/PFLlib/system/main.py", line 375, in run
    server.train()
  File "/home/student/R/fl/PFLlib/system/flcore/servers/serveravg.py", line 567, in train
    thread_batch1.join()
  File "/usr/lib/python3.9/threading.py", line 1060, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.9/threading.py", line 1080, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
Exception ignored in: <module 'threading' from '/usr/lib/python3.9/threading.py'>
Traceback (most recent call last):
  File "/usr/lib/python3.9/threading.py", line 1477, in _shutdown
    lock.acquire()
KeyboardInterrupt: