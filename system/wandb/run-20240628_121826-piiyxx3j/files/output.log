SimpleCnn(
  (conv1): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=1568, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
cuda is not avaiable.
==================================================
Algorithm: FedAvg
Local batch size: 10
Local epochs: 1
Local learing rate: 0.005
Local learing rate decay: False
Total number of clients: 20
Clients join in each round: 1.0
Clients randomly join: False
Client drop rate: 0.0
Client select regarding time: False
Running times: 1
Dataset: BloodMNIST
Number of classes: 10
Backbone: resnet18
Using device: cpu
Using DP: False
Auto break: False
Global rounds: 100
DLG attack: False
Total number of new clients: 0
Fine tuning epoches on new clients: 0
==================================================
============= Running time: 0th =============
Creating server and clients ...
x(
  (conv1): Conv2d(28, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): a(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): a(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): a(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (linear): Linear(in_features=512, out_features=10, bias=True)
  (fc): Linear(in_features=10, out_features=10, bias=True)
)
Join ratio / total clients: 1.0 / 20
Finished creating server and clients.
Dropped clients: [13, 19, 1, 4, 10, 2, 7, 18, 14, 6]
drop classif com
-------------Round number: 0-------------
Evaluate global model
Averaged Train Loss: 2.2691
Averaged Test Accurancy: 0.0703
Averaged Test AUC: 0.5693
Std Test Accurancy: 0.0527
Std Test AUC: 0.0483
clients: 10
Training client: 0, Time Cost: 2.806915044784546, Train Accuracy: 22.69%
Training client: 3, Time Cost: 3.3412718772888184, Train Accuracy: 43.87%
Training client: 5, Time Cost: 1.4035797119140625, Train Accuracy: 26.15%
Training client: 8, Time Cost: 3.3130059242248535, Train Accuracy: 23.33%
Training client: 9, Time Cost: 2.630784273147583, Train Accuracy: 28.33%
Training client: 11, Time Cost: 3.834179401397705, Train Accuracy: 46.76%
Training client: 12, Time Cost: 3.4288344383239746, Train Accuracy: 36.13%
Training client: 15, Time Cost: 4.248391389846802, Train Accuracy: 53.08%
Training client: 16, Time Cost: 3.377662420272827, Train Accuracy: 37.33%
Training client: 17, Time Cost: 4.267747640609741, Train Accuracy: 26.47%
length of uploaded models 20
Dropped clients: [2, 11, 9, 6, 13, 1, 17, 4, 7, 0]
drop classif com
-------------Round number: 1-------------
Evaluate global model
Traceback (most recent call last):
  File "/home/student/R/fl/PFLlib/system/main.py", line 549, in <module>
    run(args)
  File "/home/student/R/fl/PFLlib/system/main.py", line 375, in run
    server.train()
  File "/home/student/R/fl/PFLlib/system/flcore/servers/serveravg.py", line 509, in train
    self.evaluate()
  File "/home/student/R/fl/PFLlib/system/flcore/servers/serverbase.py", line 258, in evaluate
    stats_train = self.train_metrics()
  File "/home/student/R/fl/PFLlib/system/flcore/servers/serverbase.py", line 247, in train_metrics
    cl, ns = c.train_metrics()
  File "/home/student/R/fl/PFLlib/system/flcore/clients/clientbase.py", line 156, in train_metrics
    output = self.model(x)
  File "/home/student/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/student/.local/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1595, in _call_impl
    hook_result = hook(self, args, result)
  File "/home/student/.local/lib/python3.9/site-packages/wandb/wandb_torch.py", line 109, in <lambda>
    lambda mod, inp, outp: parameter_log_hook(
  File "/home/student/.local/lib/python3.9/site-packages/wandb/wandb_torch.py", line 104, in parameter_log_hook
    self.log_tensor_stats(data.cpu(), "parameters/" + prefix + name)
  File "/home/student/.local/lib/python3.9/site-packages/wandb/wandb_torch.py", line 247, in log_tensor_stats
    wandb.run._log(
  File "/home/student/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1641, in _log
    self._partial_history_callback(data, step, commit)
  File "/home/student/.local/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 1513, in _partial_history_callback
    self._backend.interface.publish_partial_history(
  File "/home/student/.local/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 600, in publish_partial_history
    data = history_dict_to_json(run, data, step=user_step, ignore_copy_err=True)
  File "/home/student/.local/lib/python3.9/site-packages/wandb/sdk/data_types/utils.py", line 52, in history_dict_to_json
    payload[key] = val_to_json(
  File "/home/student/.local/lib/python3.9/site-packages/wandb/sdk/data_types/utils.py", line 82, in val_to_json
    if util.is_pandas_data_frame(val):
  File "/home/student/.local/lib/python3.9/site-packages/wandb/util.py", line 459, in is_pandas_data_frame
    import pandas as pd
  File "/home/student/.local/lib/python3.9/site-packages/pandas/__init__.py", line 22, in <module>
    from pandas.compat import is_numpy_dev as _is_numpy_dev
  File "/home/student/.local/lib/python3.9/site-packages/pandas/compat/__init__.py", line 15, in <module>
    from pandas.compat.numpy import (
  File "/home/student/.local/lib/python3.9/site-packages/pandas/compat/numpy/__init__.py", line 4, in <module>
    from pandas.util.version import Version
  File "/home/student/.local/lib/python3.9/site-packages/pandas/util/__init__.py", line 1, in <module>
    from pandas.util._decorators import (  # noqa:F401
  File "/home/student/.local/lib/python3.9/site-packages/pandas/util/_decorators.py", line 14, in <module>
    from pandas._libs.properties import cache_readonly  # noqa:F401
  File "/home/student/.local/lib/python3.9/site-packages/pandas/_libs/__init__.py", line 13, in <module>
    from pandas._libs.interval import Interval
  File "pandas/_libs/interval.pyx", line 1, in init pandas._libs.interval
ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject