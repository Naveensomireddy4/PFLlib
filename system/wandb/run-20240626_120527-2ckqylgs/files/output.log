SimpleCnn(
  (conv1): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=1568, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
cuda is not avaiable.
==================================================
Algorithm: FedAvg
Local batch size: 10
Local epochs: 1
Local learing rate: 0.005
Local learing rate decay: False
Total number of clients: 20
Clients join in each round: 1.0
Clients randomly join: False
Client drop rate: 0.0
Client select regarding time: False
Running times: 1
Dataset: BloodMNIST
Number of classes: 10
Backbone: resnet18
Using device: cpu
Using DP: False
Auto break: False
Global rounds: 20
DLG attack: False
Total number of new clients: 0
Fine tuning epoches on new clients: 0
==================================================
============= Running time: 0th =============
Creating server and clients ...
x(
  (conv1): Conv2d(28, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): a(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): a(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): a(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (linear): Linear(in_features=512, out_features=10, bias=True)
  (fc): Linear(in_features=10, out_features=10, bias=True)
)
Join ratio / total clients: 1.0 / 20
Finished creating server and clients.
Dropped clients: [19, 10, 7, 12, 2, 0, 9, 3, 15, 11]
drop classif com
-------------Round number: 0-------------
Evaluate global model
Averaged Train Loss: 2.2691
Averaged Test Accurancy: 0.0703
Averaged Test AUC: 0.5693
Std Test Accurancy: 0.0527
Std Test AUC: 0.0483
clients: 10
Training client: 1, Time Cost: 3.247404098510742, Train Accuracy: 50.00%
Training client: 4, Time Cost: 3.3886687755584717, Train Accuracy: 37.00%
Training client: 5, Time Cost: 1.4957201480865479, Train Accuracy: 26.15%
Training client: 6, Time Cost: 2.1694118976593018, Train Accuracy: 24.74%
Training client: 8, Time Cost: 3.2047231197357178, Train Accuracy: 24.67%
Training client: 13, Time Cost: 3.8372445106506348, Train Accuracy: 48.61%
Training client: 14, Time Cost: 3.7663581371307373, Train Accuracy: 25.48%
Training client: 16, Time Cost: 3.2850446701049805, Train Accuracy: 39.00%
Training client: 17, Time Cost: 3.771723747253418, Train Accuracy: 34.41%
Training client: 18, Time Cost: 2.6843314170837402, Train Accuracy: 38.75%
length of uploaded models 20
Dropped clients: [18, 17, 1, 19, 16, 7, 4, 5, 9, 13]
drop classif com
-------------Round number: 1-------------
Evaluate global model
Averaged Train Loss: 2.1886
Averaged Test Accurancy: 0.2104
Averaged Test AUC: 0.6947
Std Test Accurancy: 0.0923
Std Test AUC: 0.0512
clients: 10
Training client: 0, Time Cost: 2.9243006706237793, Train Accuracy: 65.77%
Training client: 2, Time Cost: 4.096374273300171, Train Accuracy: 56.11%
Training client: 3, Time Cost: 3.4465527534484863, Train Accuracy: 72.26%
Training client: 6, Time Cost: 2.0986623764038086, Train Accuracy: 45.79%
Training client: 8, Time Cost: 3.435370445251465, Train Accuracy: 47.00%
Training client: 10, Time Cost: 3.6700339317321777, Train Accuracy: 74.55%
Training client: 11, Time Cost: 4.9826438426971436, Train Accuracy: 67.35%
Training client: 12, Time Cost: 4.648992300033569, Train Accuracy: 59.35%
Training client: 14, Time Cost: 5.007083415985107, Train Accuracy: 61.61%
Training client: 15, Time Cost: 5.967717170715332, Train Accuracy: 65.64%
length of uploaded models 20
Dropped clients: [6, 16, 10, 11, 1, 13, 17, 14, 3, 5]
drop classif com
-------------Round number: 2-------------
Evaluate global model
Averaged Train Loss: 1.5070
Averaged Test Accurancy: 0.4481
Averaged Test AUC: 0.8529
Std Test Accurancy: 0.1407
Std Test AUC: 0.0714
clients: 10
Training client: 0, Time Cost: 3.141446113586426, Train Accuracy: 62.69%
Training client: 2, Time Cost: 4.2310707569122314, Train Accuracy: 62.22%
Training client: 4, Time Cost: 3.472062826156616, Train Accuracy: 51.33%
Training client: 7, Time Cost: 3.3728301525115967, Train Accuracy: 75.36%
Training client: 8, Time Cost: 3.4515862464904785, Train Accuracy: 59.67%
Training client: 9, Time Cost: 3.217319965362549, Train Accuracy: 68.75%
Training client: 12, Time Cost: 4.119646310806274, Train Accuracy: 64.19%
Training client: 15, Time Cost: 4.784852504730225, Train Accuracy: 62.82%
Training client: 18, Time Cost: 2.6943039894104004, Train Accuracy: 66.25%
Training client: 19, Time Cost: 68.13031649589539, Train Accuracy: 60.99%
length of uploaded models 20
Dropped clients: [6, 3, 18, 9, 11, 10, 4, 0, 16, 19]
drop classif com
-------------Round number: 3-------------
Evaluate global model
Averaged Train Loss: 2.6315
Averaged Test Accurancy: 0.4022
Averaged Test AUC: 0.8265
Std Test Accurancy: 0.1233
Std Test AUC: 0.0681
clients: 10
Training client: 1, Time Cost: 4.039269208908081, Train Accuracy: 83.10%
Training client: 2, Time Cost: 4.185787200927734, Train Accuracy: 76.39%
Training client: 5, Time Cost: 1.552565336227417, Train Accuracy: 86.92%
Training client: 7, Time Cost: 3.4522721767425537, Train Accuracy: 61.79%
Training client: 8, Time Cost: 3.503420829772949, Train Accuracy: 75.33%
Training client: 12, Time Cost: 3.893712043762207, Train Accuracy: 78.39%
Training client: 13, Time Cost: 4.084869623184204, Train Accuracy: 58.06%
Training client: 14, Time Cost: 3.797215223312378, Train Accuracy: 63.87%
Training client: 15, Time Cost: 4.464110374450684, Train Accuracy: 68.21%
Training client: 17, Time Cost: 4.1378867626190186, Train Accuracy: 69.71%
length of uploaded models 20
Dropped clients: [12, 17, 18, 8, 16, 19, 13, 3, 5, 14]
drop classif com
-------------Round number: 4-------------
Evaluate global model
Averaged Train Loss: 0.7661
Averaged Test Accurancy: 0.7374
Averaged Test AUC: 0.9492
Std Test Accurancy: 0.1043
Std Test AUC: 0.0345
clients: 10
Training client: 0, Time Cost: 2.873044729232788, Train Accuracy: 43.46%
Training client: 1, Time Cost: 3.5575852394104004, Train Accuracy: 86.90%
Training client: 2, Time Cost: 3.988126754760742, Train Accuracy: 84.72%
Training client: 4, Time Cost: 3.637376070022583, Train Accuracy: 73.33%
Training client: 6, Time Cost: 2.0984432697296143, Train Accuracy: 81.58%
Training client: 7, Time Cost: 3.135042905807495, Train Accuracy: 80.00%
Training client: 9, Time Cost: 3.060730218887329, Train Accuracy: 64.58%
Training client: 10, Time Cost: 3.6377995014190674, Train Accuracy: 68.18%
Training client: 11, Time Cost: 4.088077783584595, Train Accuracy: 61.47%
Exception in thread Thread-11:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
Exception in thread Thread-12:
Traceback (most recent call last):
  File "/usr/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.8/threading.py", line 870, in run
    self.run()
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.8/threading.py", line 870, in run
  File "/home/student/R/fl/PFLlib/system/flcore/servers/serveravg.py", line 453, in train_batch
    self._target(*self._args, **self._kwargs)
    drop_len = dr*len(batch_clients)
  File "/home/student/R/fl/PFLlib/system/flcore/servers/serveravg.py", line 453, in train_batch
TypeError: object of type 'NoneType' has no len()
    drop_len = dr*len(batch_clients)
TypeError: object of type 'NoneType' has no len()
Training client: 15, Time Cost: 4.302331209182739, Train Accuracy: 85.13%
length of uploaded models 20
Batch 1 clients: [3, 1, 7, 8, 18, 5, 16, 2, 0, 9, 6, 4]
Batch 2 clients: [10, 11, 12, 13, 14, 15, 17, 19]
hello
Training round 1/37 for batch 3
Training round 1/9 for batch 10
Evaluate global model
Traceback (most recent call last):
  File "main.py", line 548, in <module>
    run(args)
  File "main.py", line 386, in run
    reporter.report()
  File "/home/student/R/fl/PFLlib/system/utils/mem_utils.py", line 220, in report
    self.print_stats(verbose, target_device=device)
  File "/home/student/R/fl/PFLlib/system/utils/mem_utils.py", line 197, in print_stats
    with torch.cuda.device(device):
  File "/home/student/.local/lib/python3.8/site-packages/torch/cuda/__init__.py", line 361, in __init__
    self.idx = _get_device_index(device, optional=True)
  File "/home/student/.local/lib/python3.8/site-packages/torch/cuda/_utils.py", line 34, in _get_device_index
    raise ValueError(f"Expected a cuda device, but got: {device}")
ValueError: Expected a cuda device, but got: meta
Traceback (most recent call last):
  File "main.py", line 548, in <module>
    run(args)
  File "main.py", line 386, in run
    reporter.report()
  File "/home/student/R/fl/PFLlib/system/utils/mem_utils.py", line 220, in report
    self.print_stats(verbose, target_device=device)
  File "/home/student/R/fl/PFLlib/system/utils/mem_utils.py", line 197, in print_stats
    with torch.cuda.device(device):
  File "/home/student/.local/lib/python3.8/site-packages/torch/cuda/__init__.py", line 361, in __init__
    self.idx = _get_device_index(device, optional=True)
  File "/home/student/.local/lib/python3.8/site-packages/torch/cuda/_utils.py", line 34, in _get_device_index
    raise ValueError(f"Expected a cuda device, but got: {device}")
ValueError: Expected a cuda device, but got: meta
Averaged Train Loss: 0.6919
Averaged Test Accurancy: 0.7447
Averaged Test AUC: 0.9558
Std Test Accurancy: 0.1117
Std Test AUC: 0.0229
length of uploaded models 10
Round time cost: 43.687793493270874
Average time cost: 535.13s.
Length:  11
std for best accurancy: 0.0
mean for best accurancy: 0.8310845874416191
All done!
Storage on cpu
-------------------------------------------------------------------------------
Total Tensors: 694107714 	Used Memory: 1.75G
-------------------------------------------------------------------------------
Storage on meta
-------------------------------------------------------------------------------
Total Tensors: 20 	Used Memory: 0.00B