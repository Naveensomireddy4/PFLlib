SimpleCnn(
  (conv1): Conv2d(28, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=1568, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
cuda is not avaiable.
==================================================
Algorithm: FedAvg
Local batch size: 10
Local epochs: 1
Local learing rate: 0.005
Local learing rate decay: False
Total number of clients: 20
Clients join in each round: 1.0
Clients randomly join: False
Client drop rate: 0.0
Client select regarding time: False
Running times: 1
Dataset: BloodMNIST
Number of classes: 10
Backbone: resnet18
Using device: cpu
Using DP: False
Auto break: False
Global rounds: 20
DLG attack: False
Total number of new clients: 0
Fine tuning epoches on new clients: 0
==================================================
============= Running time: 0th =============
Creating server and clients ...
x(
  (conv1): Conv2d(28, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (1): a(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): a(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): a(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): a(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): a(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (linear): Linear(in_features=512, out_features=10, bias=True)
  (fc): Linear(in_features=10, out_features=10, bias=True)
)
Join ratio / total clients: 1.0 / 20
Finished creating server and clients.
Dropped clients: [11, 13, 16, 12, 14, 4, 17, 18, 8, 5]
drop classif com
-------------Round number: 0-------------
Evaluate global model
Averaged Train Loss: 2.2691
Averaged Test Accurancy: 0.0703
Averaged Test AUC: 0.5693
Std Test Accurancy: 0.0527
Std Test AUC: 0.0483
clients: 10
Training client: 0, Time Cost: 2.859612226486206, Train Accuracy: 22.69%
Training client: 1, Time Cost: 3.1883251667022705, Train Accuracy: 32.76%
Training client: 2, Time Cost: 4.040524959564209, Train Accuracy: 40.28%
Training client: 3, Time Cost: 3.4408581256866455, Train Accuracy: 28.39%
Training client: 6, Time Cost: 2.170715808868408, Train Accuracy: 24.74%
Training client: 7, Time Cost: 3.1242868900299072, Train Accuracy: 22.86%
Training client: 9, Time Cost: 2.702711820602417, Train Accuracy: 28.75%
Training client: 10, Time Cost: 3.638111114501953, Train Accuracy: 40.91%
Training client: 15, Time Cost: 4.295856714248657, Train Accuracy: 48.72%
Training client: 19, Time Cost: 64.6702401638031, Train Accuracy: 72.05%
length of uploaded models 20
Batch 1 clients: [0, 3, 12, 1, 9, 6, 16, 7, 5, 14, 11, 2, 8, 17, 18, 4, 13]
Batch 2 clients: [10, 15, 19]
hello
Batch 1 clients: [0, 3, 12, 1, 9, 6, 16, 7, 5, 14, 11, 2, 8, 17, 18, 4, 13]
Batch 2 clients: [10, 15, 19]
Training round 1/191 for batch 0
<class 'list'>
......................... 8.5 .........................
Training round 1/9 for batch 10
<class 'list'>
......................... 1.5 .........................
Training client: 5, Time Cost: 19.95835304260254, Train Accuracy: 32.31%
Training client: 18, Time Cost: 33.8530387878418, Train Accuracy: 82.92%
Training client: 15, Time Cost: 43.634284257888794, Train Accuracy: 77.18%
Training client: 4, Time Cost: 39.45546007156372, Train Accuracy: 70.33%
Training client: 8, Time Cost: 39.645336866378784, Train Accuracy: 62.00%
Training client: 14, Time Cost: 39.934123516082764, Train Accuracy: 51.94%
Training client: 11, Time Cost: 41.698270082473755, Train Accuracy: 79.12%
Training client: 17, Time Cost: 41.912832260131836, Train Accuracy: 79.71%
Training client: 13, Time Cost: 42.36979413032532, Train Accuracy: 83.33%
Training client: 2, Time Cost: 42.443673849105835, Train Accuracy: 74.72%
length of uploaded models 20
Training round 2/191 for batch 0
<class 'list'>
......................... 8.5 .........................
